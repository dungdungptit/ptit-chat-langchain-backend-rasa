{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import underthesea\n",
    "import numpy as np\n",
    "from underthesea import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['địa chỉ', 'nhà', 'tôi', 'ở', 'học bạ']\n"
     ]
    }
   ],
   "source": [
    "text = \"địa chỉ nhà tôi ở học bạ\"\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "địa_chỉ nhà tôi ở học_bạ\n",
      "['địa_chỉ', 'nhà', 'tôi', 'ở', 'học_bạ']\n"
     ]
    }
   ],
   "source": [
    "print(ViTokenizer.tokenize(text))\n",
    "print(ViTokenizer.tokenize(text).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer\n",
    "from pyvi.ViTokenizer import tokenize\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "# Create your views here.\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('<.*?>', '', text).strip()\n",
    "    text = re.sub('(\\s)+', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "def sentence_segment(text):\n",
    "    sents = re.split(\"([.?!])?[\\n]+|[.?!] \", text)\n",
    "    return sents\n",
    "\n",
    "def word_segment(sent): # chuyển câu thành từ\n",
    "    sent = tokenize(sent)\n",
    "    return sent\n",
    "\n",
    "def normalize_text(text):\n",
    "    listpunctuation = string.punctuation.replace('_', '')\n",
    "    for i in listpunctuation:\n",
    "        text = text.replace(i, ' ')\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def remove_numbers(text_in):\n",
    "  for ele in text_in.split(): \n",
    "    if ele.isdigit():\n",
    "        text_in = text_in.replace(ele, \"@\")\n",
    "  for character in text_in:\n",
    "    if character.isdigit():\n",
    "        text_in = text_in.replace(character, \"@\")\n",
    "  return text_in\n",
    "\n",
    "\n",
    "def remove_special_characters(text):\n",
    "  chars = re.escape(string.punctuation)\n",
    "  return re.sub(r'['+chars+']', '', text)\n",
    "\n",
    " \n",
    "def preprocess(text_in):  \n",
    "    text = clean_text(text_in)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_numbers(text) \n",
    "    return text\n",
    "\n",
    "# data_stopwords = pd.read_csv('../FastText_v1/stopwords.csv')\n",
    "# list_stopwords = data_stopwords['stopwords'].values.tolist()\n",
    "# def remove_stopword(text):\n",
    "#     text = ' '.join([i for i in text.split() if i not in list_stopwords])\n",
    "#     return text\n",
    "\n",
    "def process_text(text):\n",
    "    text = clean_text(text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = word_segment(text)\n",
    "    text = normalize_text(text)\n",
    "    # text = remove_stopword(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "địa_chỉ nhà tôi ở học_bạ\n"
     ]
    }
   ],
   "source": [
    "print(process_text(text))\n",
    "text = process_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['địa_chỉ', 'nhà', 'tôi', 'ở', 'học_bạ']\n"
     ]
    }
   ],
   "source": [
    "words = text.split()\n",
    "\n",
    "words = [w for w in words if w]\n",
    "print(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
